// responseGenerator.js
import { getGenerativeModel, generateContentWithRetry } from "./chatAPI";
import { isTextObjectionable } from "./chatUtils";
import { parseSuggestions } from "./chatParser";
import { filterPrompt, generatePrompt } from "./prompts";
import { warningText } from "./warnings";

const MAX_REQUESTS = 5;
const filterAndCheckUserInput = async (userInput) => {
    const filterModel = getGenerativeModel({ model: "gemini-pro" }); 
    const filterPromptResult = await filterPrompt(userInput)
    const filterResult = await generateContentWithRetry(filterModel, filterPromptResult, MAX_REQUESTS);
    const filteredResultText = await filterResult.response.text();
  
    if (isTextObjectionable(filteredResultText)) {
      console.warn(warningText);
      return null; 
    }
  
    return filteredResultText;
  }
  
export const generateResponse = async (userInput, chatHistory, setChatHistory, setSuggestedResponses) => {
    if (!userInput.trim()) {
      throw new Error("User input cannot be empty");
    }
  
    const filteredResultText = await filterAndCheckUserInput(userInput);
  
    if (!filteredResultText) {
      setSuggestedResponses([""]);
      return; 
    }
  
    const model = getGenerativeModel({ model: "gemini-pro" });
    const prompt = generatePrompt(userInput, chatHistory);
  
    const result = await generateContentWithRetry(model, prompt, MAX_REQUESTS);
  
    handleGeneratedResponse(result, userInput, setChatHistory, setSuggestedResponses);
  };
  

  



const handleGeneratedResponse = (result, userInput, setChatHistory, setSuggestedResponses) => {
  let botResponse = result?.response?.text();

  if (botResponse) {
    setChatHistory(prevChatHistory => [...prevChatHistory, { user: userInput, bot: botResponse }]);
    setSuggestedResponses(parseSuggestions(botResponse));
  } else {
    console.warn("No text was generated by the AI model.");
  }
};
